import pytest
import asyncio
import aiohttp
import os
from unittest.mock import patch, AsyncMock
from bot import ChatBot

@pytest.fixture
def chat_bot():
    """Ð¤Ð¸ÐºÑÑ‚ÑƒÑ€Ð° Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€Ð° Ð±Ð¾Ñ‚Ð°"""
    return ChatBot()

@pytest.fixture
def mock_ollama_response():
    """ÐœÐ¾Ðº Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ Ollama"""
    return {
        "response": "ÐŸÑ€Ð¸Ð²ÐµÑ‚! ÐšÐ°Ðº Ð´ÐµÐ»Ð°? Ð Ð°Ð´ Ñ‚ÐµÐ±Ñ Ð²Ð¸Ð´ÐµÑ‚ÑŒ!",
        "done": True
    }

@pytest.mark.unit
class TestChatBot:
    """Unit Ñ‚ÐµÑÑ‚Ñ‹ Ð´Ð»Ñ ChatBot"""
    
    def test_bot_initialization(self, chat_bot):
        """Ð¢ÐµÑÑ‚ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ð¸ Ð±Ð¾Ñ‚Ð°"""
        assert chat_bot.ollama_url == os.getenv('OLLAMA_URL', 'http://localhost:11434')
        assert chat_bot.model_name == os.getenv('OLLAMA_MODEL', 'llama2:7b')
        assert chat_bot.use_llm == (os.getenv('USE_LLM', 'true').lower() == 'true')
    
    @pytest.mark.parametrize("input_text,expected_keywords", [
        ("ÐŸÑ€Ð¸Ð²ÐµÑ‚!", ["Ð¿Ñ€Ð¸Ð²ÐµÑ‚", "Ñ€Ð°Ð´", "Ð²Ð¸Ð´ÐµÑ‚ÑŒ"]),
        ("ÐšÐ°Ðº Ð´ÐµÐ»Ð°?", ["Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾", "Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾", "ÑÐ¿Ð°ÑÐ¸Ð±Ð¾"]),
        ("Ð¡Ð¿Ð°ÑÐ¸Ð±Ð¾!", ["Ð¿Ð¾Ð¶Ð°Ð»ÑƒÐ¹ÑÑ‚Ð°", "Ñ€Ð°Ð´", "Ð¿Ð¾Ð¼Ð¾Ñ‡ÑŒ"]),
        ("ÐŸÐ¾ÐºÐ°!", ["Ð´Ð¾ ÑÐ²Ð¸Ð´Ð°Ð½Ð¸Ñ", "Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸", "Ð´Ð½Ñ"]),
    ])
    def test_fallback_response_keywords(self, chat_bot, input_text, expected_keywords):
        """Ð¢ÐµÑÑ‚ fallback Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° ÐºÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°"""
        response = chat_bot.get_fallback_response(input_text)
        assert any(word in response.lower() for word in expected_keywords)
    
    @pytest.mark.parametrize("input_text", [
        "Ð§Ñ‚Ð¾ Ñ‚Ñ‹ Ð´ÑƒÐ¼Ð°ÐµÑˆÑŒ?",
        "ÐšÐ°Ðº ÑÑ‚Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ð°ÐµÑ‚?",
        "ÐŸÐ¾Ñ‡ÐµÐ¼Ñƒ Ñ‚Ð°Ðº Ð¿Ñ€Ð¾Ð¸ÑÑ…Ð¾Ð´Ð¸Ñ‚?",
    ])
    def test_fallback_response_questions(self, chat_bot, input_text):
        """Ð¢ÐµÑÑ‚ fallback Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° Ð²Ð¾Ð¿Ñ€Ð¾ÑÑ‹"""
        response = chat_bot.get_fallback_response(input_text)
        assert "?" in response or "Ñ€Ð°ÑÑÐºÐ°Ð¶Ð¸" in response.lower()
    
    @pytest.mark.parametrize("input_text,expected_emotion", [
        ("Ð¯ Ñ€Ð°Ð´! ðŸ˜Š", ["Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ", "Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾"]),
        ("ÐœÐ½Ðµ Ð³Ñ€ÑƒÑÑ‚Ð½Ð¾ ðŸ˜¢", ["Ð³Ñ€ÑƒÑÑ‚Ð¸", "Ñ…Ð¾Ñ€Ð¾ÑˆÐ¾"]),
        ("Ð¯ ÑÑ‡Ð°ÑÑ‚Ð»Ð¸Ð²! ðŸ˜", ["Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ", "Ð¾Ñ‚Ð»Ð¸Ñ‡Ð½Ð¾"]),
    ])
    def test_fallback_response_emotions(self, chat_bot, input_text, expected_emotion):
        """Ð¢ÐµÑÑ‚ fallback Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð½Ð° ÑÐ¼Ð¾Ñ†Ð¸Ð¸"""
        response = chat_bot.get_fallback_response(input_text)
        assert any(word in response.lower() for word in expected_emotion)
    
    @pytest.mark.asyncio
    async def test_llm_response_success(self, chat_bot, mock_ollama_response):
        """Ð¢ÐµÑÑ‚ ÑƒÑÐ¿ÐµÑˆÐ½Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¾Ñ‚ LLM"""
        with patch('aiohttp.ClientSession') as mock_session:
            mock_session.return_value.__aenter__.return_value.post.return_value.__aenter__.return_value.status = 200
            mock_session.return_value.__aenter__.return_value.post.return_value.__aenter__.return_value.json = AsyncMock(return_value=mock_ollama_response)
            
            response = await chat_bot.get_llm_response("ÐŸÑ€Ð¸Ð²ÐµÑ‚!")
            assert response == "ÐŸÑ€Ð¸Ð²ÐµÑ‚! ÐšÐ°Ðº Ð´ÐµÐ»Ð°? Ð Ð°Ð´ Ñ‚ÐµÐ±Ñ Ð²Ð¸Ð´ÐµÑ‚ÑŒ!"
    
    @pytest.mark.asyncio
    async def test_llm_response_error(self, chat_bot):
        """Ð¢ÐµÑÑ‚ Ð¾ÑˆÐ¸Ð±ÐºÐ¸ Ð¿Ñ€Ð¸ Ð¾Ð±Ñ€Ð°Ñ‰ÐµÐ½Ð¸Ð¸ Ðº LLM"""
        with patch('aiohttp.ClientSession') as mock_session:
            mock_session.return_value.__aenter__.return_value.post.return_value.__aenter__.return_value.status = 404
            
            response = await chat_bot.get_llm_response("ÐŸÑ€Ð¸Ð²ÐµÑ‚!")
            assert response is None
    
    @pytest.mark.asyncio
    async def test_llm_disabled(self, chat_bot):
        """Ð¢ÐµÑÑ‚ Ð¾Ñ‚ÐºÐ»ÑŽÑ‡ÐµÐ½Ð½Ð¾Ð³Ð¾ LLM"""
        chat_bot.use_llm = False
        response = await chat_bot.get_llm_response("ÐŸÑ€Ð¸Ð²ÐµÑ‚!")
        assert response is None
    
    @pytest.mark.asyncio
    async def test_get_response_with_llm(self, chat_bot, mock_ollama_response):
        """Ð¢ÐµÑÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ñ LLM"""
        with patch('aiohttp.ClientSession') as mock_session:
            mock_session.return_value.__aenter__.return_value.post.return_value.__aenter__.return_value.status = 200
            mock_session.return_value.__aenter__.return_value.post.return_value.__aenter__.return_value.json = AsyncMock(return_value=mock_ollama_response)
            
            response = await chat_bot.get_response("ÐŸÑ€Ð¸Ð²ÐµÑ‚!")
            assert "ÐŸÑ€Ð¸Ð²ÐµÑ‚! ÐšÐ°Ðº Ð´ÐµÐ»Ð°? Ð Ð°Ð´ Ñ‚ÐµÐ±Ñ Ð²Ð¸Ð´ÐµÑ‚ÑŒ!" in response
    
    @pytest.mark.asyncio
    async def test_get_response_fallback(self, chat_bot):
        """Ð¢ÐµÑÑ‚ Ð¿Ð¾Ð»ÑƒÑ‡ÐµÐ½Ð¸Ñ fallback Ð¾Ñ‚Ð²ÐµÑ‚Ð°"""
        with patch('aiohttp.ClientSession') as mock_session:
            mock_session.return_value.__aenter__.return_value.post.return_value.__aenter__.return_value.status = 404
            
            response = await chat_bot.get_response("ÐŸÑ€Ð¸Ð²ÐµÑ‚!")
            assert any(word in response.lower() for word in ["Ð¿Ñ€Ð¸Ð²ÐµÑ‚", "Ñ€Ð°Ð´", "Ð²Ð¸Ð´ÐµÑ‚ÑŒ"])

@pytest.mark.integration
class TestBotIntegration:
    """Ð˜Ð½Ñ‚ÐµÐ³Ñ€Ð°Ñ†Ð¸Ð¾Ð½Ð½Ñ‹Ðµ Ñ‚ÐµÑÑ‚Ñ‹"""
    
    @pytest.mark.asyncio
    @pytest.mark.parametrize("input_text", [
        "ÐŸÑ€Ð¸Ð²ÐµÑ‚",
        "Ð§Ñ‚Ð¾ Ñ‚Ñ‹ ÑƒÐ¼ÐµÐµÑˆÑŒ?",
        "Ð­Ñ‚Ð¾ Ð¾Ñ‡ÐµÐ½ÑŒ Ð´Ð»Ð¸Ð½Ð½Ð¾Ðµ ÑÐ¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ Ñ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ð¾Ð¼ ÑÐ»Ð¾Ð² Ð¸ Ð´ÐµÑ‚Ð°Ð»ÐµÐ¹, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð²Ñ‹Ð·Ð²Ð°Ñ‚ÑŒ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð½ÑƒÑŽ Ñ€ÐµÐ°ÐºÑ†Ð¸ÑŽ Ñƒ Ð±Ð¾Ñ‚Ð°",
        "ÐœÐ½Ðµ 25 Ð»ÐµÑ‚",
    ])
    async def test_bot_response_types(self, chat_bot, input_text):
        """Ð¢ÐµÑÑ‚ Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ñ‚Ð¸Ð¿Ð¾Ð² Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð² Ð±Ð¾Ñ‚Ð°"""
        response = await chat_bot.get_response(input_text)
        assert len(response) > 0
        assert isinstance(response, str)

@pytest.mark.slow
class TestBotPerformance:
    """Ð¢ÐµÑÑ‚Ñ‹ Ð¿Ñ€Ð¾Ð¸Ð·Ð²Ð¾Ð´Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ÑÑ‚Ð¸ (Ð¼ÐµÐ´Ð»ÐµÐ½Ð½Ñ‹Ðµ)"""
    
    @pytest.mark.asyncio
    async def test_multiple_responses(self, chat_bot):
        """Ð¢ÐµÑÑ‚ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²ÐµÐ½Ð½Ñ‹Ñ… Ð¾Ñ‚Ð²ÐµÑ‚Ð¾Ð²"""
        responses = []
        for i in range(5):
            response = await chat_bot.get_response(f"Ð¡Ð¾Ð¾Ð±Ñ‰ÐµÐ½Ð¸Ðµ {i}")
            responses.append(response)
        
        assert len(responses) == 5
        assert all(len(r) > 0 for r in responses)

if __name__ == "__main__":
    pytest.main([__file__, "-v"]) 