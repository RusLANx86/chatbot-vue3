import random
import re
import os
import aiohttp
import asyncio
from typing import Optional

class ChatBot:
    def __init__(self):
        self.ollama_url = os.getenv('OLLAMA_URL', 'http://localhost:11434')
        self.model_name = os.getenv('OLLAMA_MODEL', 'llama2:7b')
        self.use_llm = os.getenv('USE_LLM', 'true').lower() == 'true'
        
        # Fallback –æ—Ç–≤–µ—Ç—ã –¥–ª—è —Å–ª—É—á–∞–µ–≤, –∫–æ–≥–¥–∞ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
        self.responses = {
            "–ø—Ä–∏–≤–µ—Ç": [
                "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –¥–µ–ª–∞?",
                "–ü—Ä–∏–≤–µ—Ç! –†–∞–¥ —Ç–µ–±—è –≤–∏–¥–µ—Ç—å!",
                "–ü—Ä–∏–≤–µ—Ç! –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
                "–ü—Ä–∏–≤–µ—Ç! –ö–∞–∫ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ?"
            ],
            "–∫–∞–∫ –¥–µ–ª–∞": [
                "–û—Ç–ª–∏—á–Ω–æ! –°–ø–∞—Å–∏–±–æ, —á—Ç–æ —Å–ø—Ä–æ—Å–∏–ª!",
                "–•–æ—Ä–æ—à–æ! –ê —É —Ç–µ–±—è –∫–∞–∫?",
                "–í—Å–µ —Å—É–ø–µ—Ä! –ì–æ—Ç–æ–≤ –∫ –æ–±—â–µ–Ω–∏—é!",
                "–ó–∞–º–µ—á–∞—Ç–µ–ª—å–Ω–æ! –ù–∞–¥–µ—é—Å—å, —É —Ç–µ–±—è —Ç–æ–∂–µ –≤—Å–µ —Ö–æ—Ä–æ—à–æ!"
            ],
            "—á—Ç–æ –¥–µ–ª–∞–µ—à—å": [
                "–û–±—â–∞—é—Å—å —Å —Ç–æ–±–æ–π! üòä",
                "–ò–∑—É—á–∞—é –Ω–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è",
                "–ü–æ–º–æ–≥–∞—é –ª—é–¥—è–º –≤ —á–∞—Ç–µ",
                "–û—Ç–≤–µ—á–∞—é –Ω–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã"
            ],
            "—Å–ø–∞—Å–∏–±–æ": [
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –†–∞–¥ –ø–æ–º–æ—á—å!",
                "–ù–µ –∑–∞ —á—Ç–æ! –û–±—Ä–∞—â–∞–π—Å—è!",
                "–°–ø–∞—Å–∏–±–æ —Ç–µ–±–µ –∑–∞ –æ–±—â–µ–Ω–∏–µ!",
                "–í—Å–µ–≥–¥–∞ —Ä–∞–¥ –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω—ã–º!"
            ],
            "–ø–æ–∫–∞": [
                "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –ë—ã–ª–æ –ø—Ä–∏—è—Ç–Ω–æ –ø–æ–æ–±—â–∞—Ç—å—Å—è!",
                "–ü–æ–∫–∞! –ù–∞–¥–µ—é—Å—å, —Å–∫–æ—Ä–æ —É–≤–∏–¥–∏–º—Å—è!",
                "–î–æ –≤—Å—Ç—Ä–µ—á–∏! –•–æ—Ä–æ—à–µ–≥–æ –¥–Ω—è!",
                "–ü–æ–∫–∞! –ù–µ —Å–∫—É—á–∞–π!"
            ]
        }
        
        self.general_responses = [
            "–ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ! –†–∞—Å—Å–∫–∞–∂–∏ –ø–æ–¥—Ä–æ–±–Ω–µ–µ.",
            "–ü–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ —Ç—ã –∏–º–µ–µ—à—å –≤ –≤–∏–¥—É.",
            "–≠—Ç–æ –æ—á–µ–Ω—å –∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –º—ã—Å–ª—å!",
            "–°–æ–≥–ª–∞—Å–µ–Ω —Å —Ç–æ–±–æ–π.",
            "–•–º, –Ω—É–∂–Ω–æ –ø–æ–¥—É–º–∞—Ç—å –æ–± —ç—Ç–æ–º.",
            "–û—Ç–ª–∏—á–Ω–∞—è –∏–¥–µ—è!",
            "–°–ø–∞—Å–∏–±–æ –∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.",
            "–≠—Ç–æ –∑–∞—Å—Ç–∞–≤–ª—è–µ—Ç –∑–∞–¥—É–º–∞—Ç—å—Å—è.",
            "–û—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ —Å–∫–∞–∑–∞–Ω–æ!",
            "–ü—Ä–æ–¥–æ–ª–∂–∞–π, –º–Ω–µ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ.",
            "–£—Ö —Ç—ã! –≠—Ç–æ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ!",
            "–Ø —Ç–æ–∂–µ —Ç–∞–∫ –¥—É–º–∞—é!",
            "–•–æ—Ä–æ—à–∏–π –≤–æ–ø—Ä–æ—Å!",
            "–î–∞–≤–∞–π—Ç–µ –æ–±—Å—É–¥–∏–º —ç—Ç–æ –ø–æ–¥—Ä–æ–±–Ω–µ–µ.",
            "–Ø –≤–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ —Å–ª—É—à–∞—é!"
        ]
        
        self.questions = [
            "–ê —á—Ç–æ —Ç—ã –¥—É–º–∞–µ—à—å –æ–± —ç—Ç–æ–º?",
            "–ö–∞–∫ —Ç—ã –∫ —ç—Ç–æ–º—É –æ—Ç–Ω–æ—Å–∏—à—å—Å—è?",
            "–†–∞—Å—Å–∫–∞–∂–∏ –±–æ–ª—å—à–µ!",
            "–≠—Ç–æ –ø—Ä–∞–≤–¥–∞ –∏–Ω—Ç–µ—Ä–µ—Å–Ω–æ!",
            "–ê —á—Ç–æ –¥–∞–ª—å—à–µ?",
            "–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç?",
            "–ü–æ—á–µ–º—É —Ç—ã —Ç–∞–∫ –¥—É–º–∞–µ—à—å?",
            "–ß—Ç–æ —Ç–µ–±—è –≤–¥–æ—Ö–Ω–æ–≤–ª—è–µ—Ç?"
        ]

    async def get_llm_response(self, message: str) -> Optional[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç Ollama LLM"""
        if not self.use_llm:
            return None
            
        try:
            async with aiohttp.ClientSession() as session:
                payload = {
                    "model": self.model_name,
                    "prompt": f"""–¢—ã –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π —á–∞—Ç-–±–æ—Ç. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ –∏ –ø–æ-—Ä—É—Å—Å–∫–∏ –Ω–∞ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.

–°–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {message}

–û—Ç–≤–µ—Ç:""",
                    "stream": False,
                    "options": {
                        "temperature": 0.7,
                        "top_p": 0.9,
                        "max_tokens": 150
                    }
                }
                
                async with session.post(
                    f"{self.ollama_url}/api/generate",
                    json=payload,
                    timeout=aiohttp.ClientTimeout(total=10)
                ) as response:
                    if response.status == 200:
                        data = await response.json()
                        return data.get('response', '').strip()
                    else:
                        print(f"Ollama API error: {response.status}")
                        return None
                        
        except Exception as e:
            print(f"Error calling Ollama API: {e}")
            return None

    def get_fallback_response(self, message: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å fallback –æ—Ç–≤–µ—Ç"""
        message_lower = message.lower().strip()
        
        for keyword, responses in self.responses.items():
            if keyword in message_lower:
                return random.choice(responses)
        
        if message_lower.endswith('?') or message_lower.startswith('—á—Ç–æ') or message_lower.startswith('–∫–∞–∫') or message_lower.startswith('–ø–æ—á–µ–º—É'):
            return random.choice(self.questions)
        
        if len(message_lower) < 10:
            return random.choice(self.general_responses)
        
        if any(emoji in message_lower for emoji in ['üòä', 'üòÑ', 'üòç', 'üòé', 'üëç', '‚ù§Ô∏è']):
            return "–û—Ç–ª–∏—á–Ω–æ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ! üòä"
        
        if any(emoji in message_lower for emoji in ['üò¢', 'üò≠', 'üòî', 'üòû', 'üíî']):
            return "–ù–µ –≥—Ä—É—Å—Ç–∏! –í—Å–µ –±—É–¥–µ—Ç —Ö–æ—Ä–æ—à–æ! üåü"
        
        if re.search(r'\d+', message_lower):
            return "–¶–∏—Ñ—Ä—ã! –ò–Ω—Ç–µ—Ä–µ—Å–Ω–æ! –†–∞—Å—Å–∫–∞–∂–∏ –±–æ–ª—å—à–µ –æ–± —ç—Ç–æ–º."
        
        if len(message_lower) > 50:
            return "–í–∞—É! –¢—ã –æ—á–µ–Ω—å –ø–æ–¥—Ä–æ–±–Ω–æ –≤—Å–µ –æ–±—ä—è—Å–Ω–∏–ª! –°–ø–∞—Å–∏–±–æ –∑–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é!"
        
        return random.choice(self.general_responses)

    async def get_response(self, message: str) -> str:
        """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –±–æ—Ç–∞ (LLM –∏–ª–∏ fallback)"""
        llm_response = await self.get_llm_response(message)
        
        if llm_response and len(llm_response) > 0:
            return llm_response
        else:
            return self.get_fallback_response(message)

    def get_response_sync(self, message: str) -> str:
        """–°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        return asyncio.run(self.get_response(message))